{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X, y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=(X - X.mean(axis=0))/X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification binaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_algo(input_dim):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    # input layers\n",
    "    model.add(tf.keras.layers.Dense(3, input_dim=input_dim, activation='sigmoid'))\n",
    "    #hidden layers\n",
    "    model.add(tf.keras.layers.Dense(3, activation='sigmoid'))\n",
    "   #model.add(tf.keras.layers.Dense(3, activation='sigmoid'))\n",
    "    #output layers\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = model_algo(input_dim=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_41 (Dense)             (None, 3)                 93        \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 109\n",
      "Trainable params: 109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.compile(optimizer='SGD', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/10\n",
      "455/455 [==============================] - 1s 3ms/sample - loss: 0.7510 - accuracy: 0.2110 - val_loss: 0.7443 - val_accuracy: 0.2193\n",
      "Epoch 2/10\n",
      "455/455 [==============================] - 0s 395us/sample - loss: 0.7416 - accuracy: 0.1802 - val_loss: 0.7380 - val_accuracy: 0.1754\n",
      "Epoch 3/10\n",
      "455/455 [==============================] - 0s 306us/sample - loss: 0.7336 - accuracy: 0.1934 - val_loss: 0.7320 - val_accuracy: 0.2105\n",
      "Epoch 4/10\n",
      "455/455 [==============================] - 0s 348us/sample - loss: 0.7259 - accuracy: 0.2527 - val_loss: 0.7264 - val_accuracy: 0.2807\n",
      "Epoch 5/10\n",
      "455/455 [==============================] - 0s 390us/sample - loss: 0.7185 - accuracy: 0.3560 - val_loss: 0.7220 - val_accuracy: 0.3684\n",
      "Epoch 6/10\n",
      "455/455 [==============================] - 0s 288us/sample - loss: 0.7129 - accuracy: 0.4549 - val_loss: 0.7181 - val_accuracy: 0.4561\n",
      "Epoch 7/10\n",
      "455/455 [==============================] - 0s 363us/sample - loss: 0.7078 - accuracy: 0.5538 - val_loss: 0.7144 - val_accuracy: 0.5175\n",
      "Epoch 8/10\n",
      "455/455 [==============================] - 0s 397us/sample - loss: 0.7027 - accuracy: 0.6176 - val_loss: 0.7111 - val_accuracy: 0.5614\n",
      "Epoch 9/10\n",
      "455/455 [==============================] - 0s 447us/sample - loss: 0.6983 - accuracy: 0.6286 - val_loss: 0.7080 - val_accuracy: 0.5877\n",
      "Epoch 10/10\n",
      "455/455 [==============================] - 0s 368us/sample - loss: 0.6942 - accuracy: 0.6374 - val_loss: 0.7052 - val_accuracy: 0.5877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1501962b38>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = my_model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.7052065238618014\n",
      "accuracy :0.5877193212509155\n"
     ]
    }
   ],
   "source": [
    "print(f'loss : {loss}')\n",
    "print(f'accuracy :{accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression binaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston().data\n",
    "target = load_boston().target\n",
    "features = load_boston().feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = pd.DataFrame(data=data, columns=features)\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_df = scaler.fit_transform(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_df, target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_five_layers(input_dim):\n",
    "    model = tf.keras.Sequential()\n",
    "    #input layers\n",
    "    model.add(tf.keras.layers.Dense(100, input_dim=input_dim, activation='sigmoid'))\n",
    "    \n",
    "    #hidden layers\n",
    "    model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "    model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "    model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "    model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "    \n",
    "    #ouput layers\n",
    "    model.add(tf.keras.layers.Dense(1, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_five = model_five_layers(input_dim=X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 100)               1400      \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 41,901\n",
      "Trainable params: 41,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model_five.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_five.compile('SGD', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples, validate on 102 samples\n",
      "Epoch 1/500\n",
      "404/404 [==============================] - 3s 7ms/sample - loss: 140.3835 - val_loss: 81.5213\n",
      "Epoch 2/500\n",
      "404/404 [==============================] - 0s 564us/sample - loss: 86.5689 - val_loss: 81.4703\n",
      "Epoch 3/500\n",
      "404/404 [==============================] - 0s 799us/sample - loss: 86.4033 - val_loss: 82.0806\n",
      "Epoch 4/500\n",
      "404/404 [==============================] - 0s 920us/sample - loss: 88.5302 - val_loss: 84.9581\n",
      "Epoch 5/500\n",
      "404/404 [==============================] - 0s 723us/sample - loss: 88.8429 - val_loss: 98.6819\n",
      "Epoch 6/500\n",
      "404/404 [==============================] - 0s 861us/sample - loss: 88.2712 - val_loss: 85.4952\n",
      "Epoch 7/500\n",
      "404/404 [==============================] - 0s 885us/sample - loss: 85.2744 - val_loss: 82.6135\n",
      "Epoch 8/500\n",
      "404/404 [==============================] - 0s 790us/sample - loss: 86.5284 - val_loss: 83.5776\n",
      "Epoch 9/500\n",
      "404/404 [==============================] - 0s 951us/sample - loss: 91.4998 - val_loss: 81.3997\n",
      "Epoch 10/500\n",
      "404/404 [==============================] - 0s 854us/sample - loss: 86.5592 - val_loss: 82.5118\n",
      "Epoch 11/500\n",
      "404/404 [==============================] - 0s 869us/sample - loss: 87.3023 - val_loss: 82.2106\n",
      "Epoch 12/500\n",
      "404/404 [==============================] - 0s 868us/sample - loss: 86.1488 - val_loss: 90.5828\n",
      "Epoch 13/500\n",
      "404/404 [==============================] - 0s 788us/sample - loss: 86.6643 - val_loss: 81.5646\n",
      "Epoch 14/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 86.7202 - val_loss: 88.7546\n",
      "Epoch 15/500\n",
      "404/404 [==============================] - 0s 810us/sample - loss: 88.3445 - val_loss: 81.3956\n",
      "Epoch 16/500\n",
      "404/404 [==============================] - 0s 836us/sample - loss: 88.5634 - val_loss: 83.5788\n",
      "Epoch 17/500\n",
      "404/404 [==============================] - 0s 751us/sample - loss: 86.5270 - val_loss: 81.5128\n",
      "Epoch 18/500\n",
      "404/404 [==============================] - 0s 764us/sample - loss: 86.2870 - val_loss: 84.3065\n",
      "Epoch 19/500\n",
      "404/404 [==============================] - 0s 926us/sample - loss: 88.9609 - val_loss: 81.3948\n",
      "Epoch 20/500\n",
      "404/404 [==============================] - 0s 920us/sample - loss: 88.0149 - val_loss: 81.4331\n",
      "Epoch 21/500\n",
      "404/404 [==============================] - 0s 945us/sample - loss: 86.8441 - val_loss: 81.8438\n",
      "Epoch 22/500\n",
      "404/404 [==============================] - 0s 857us/sample - loss: 89.3046 - val_loss: 81.3622\n",
      "Epoch 23/500\n",
      "404/404 [==============================] - 0s 819us/sample - loss: 86.7769 - val_loss: 82.5062\n",
      "Epoch 24/500\n",
      "404/404 [==============================] - 0s 828us/sample - loss: 88.8719 - val_loss: 86.5042\n",
      "Epoch 25/500\n",
      "404/404 [==============================] - 0s 928us/sample - loss: 85.3371 - val_loss: 82.2430\n",
      "Epoch 26/500\n",
      "404/404 [==============================] - 0s 888us/sample - loss: 88.4414 - val_loss: 82.2805\n",
      "Epoch 27/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 85.7914 - val_loss: 81.0598\n",
      "Epoch 28/500\n",
      "404/404 [==============================] - 0s 998us/sample - loss: 85.7155 - val_loss: 100.8111\n",
      "Epoch 29/500\n",
      "404/404 [==============================] - 0s 784us/sample - loss: 87.4061 - val_loss: 81.1902\n",
      "Epoch 30/500\n",
      "404/404 [==============================] - 0s 939us/sample - loss: 86.3127 - val_loss: 81.5855\n",
      "Epoch 31/500\n",
      "404/404 [==============================] - 0s 981us/sample - loss: 85.0269 - val_loss: 80.3977\n",
      "Epoch 32/500\n",
      "404/404 [==============================] - 0s 916us/sample - loss: 86.9264 - val_loss: 84.8361\n",
      "Epoch 33/500\n",
      "404/404 [==============================] - 0s 822us/sample - loss: 86.1729 - val_loss: 80.1005\n",
      "Epoch 34/500\n",
      "404/404 [==============================] - 0s 958us/sample - loss: 81.9542 - val_loss: 78.2660\n",
      "Epoch 35/500\n",
      "404/404 [==============================] - 0s 844us/sample - loss: 77.5419 - val_loss: 74.8149\n",
      "Epoch 36/500\n",
      "404/404 [==============================] - 0s 881us/sample - loss: 70.9305 - val_loss: 67.3646\n",
      "Epoch 37/500\n",
      "404/404 [==============================] - 0s 802us/sample - loss: 59.1575 - val_loss: 69.0808\n",
      "Epoch 38/500\n",
      "404/404 [==============================] - 0s 942us/sample - loss: 47.7767 - val_loss: 76.5948\n",
      "Epoch 39/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 49.5500 - val_loss: 49.7771\n",
      "Epoch 40/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 37.7866 - val_loss: 47.2870\n",
      "Epoch 41/500\n",
      "404/404 [==============================] - 0s 799us/sample - loss: 39.1688 - val_loss: 43.1275\n",
      "Epoch 42/500\n",
      "404/404 [==============================] - 0s 815us/sample - loss: 24.3617 - val_loss: 43.3301\n",
      "Epoch 43/500\n",
      "404/404 [==============================] - 0s 881us/sample - loss: 31.3658 - val_loss: 43.1092\n",
      "Epoch 44/500\n",
      "404/404 [==============================] - 0s 773us/sample - loss: 22.1441 - val_loss: 40.0848\n",
      "Epoch 45/500\n",
      "404/404 [==============================] - 0s 866us/sample - loss: 41.8106 - val_loss: 43.7331\n",
      "Epoch 46/500\n",
      "404/404 [==============================] - 0s 905us/sample - loss: 26.9567 - val_loss: 44.5397\n",
      "Epoch 47/500\n",
      "404/404 [==============================] - 0s 940us/sample - loss: 27.2465 - val_loss: 39.7101\n",
      "Epoch 48/500\n",
      "404/404 [==============================] - 0s 928us/sample - loss: 22.1656 - val_loss: 39.2596\n",
      "Epoch 49/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 23.3883 - val_loss: 35.8827\n",
      "Epoch 50/500\n",
      "404/404 [==============================] - 0s 810us/sample - loss: 24.8922 - val_loss: 37.7320\n",
      "Epoch 51/500\n",
      "404/404 [==============================] - 0s 764us/sample - loss: 27.6320 - val_loss: 48.9120\n",
      "Epoch 52/500\n",
      "404/404 [==============================] - 0s 541us/sample - loss: 27.1651 - val_loss: 32.3050\n",
      "Epoch 53/500\n",
      "404/404 [==============================] - 0s 695us/sample - loss: 28.7129 - val_loss: 43.7890\n",
      "Epoch 54/500\n",
      "404/404 [==============================] - 0s 694us/sample - loss: 20.4376 - val_loss: 34.1790\n",
      "Epoch 55/500\n",
      "404/404 [==============================] - 0s 557us/sample - loss: 20.7901 - val_loss: 38.5377\n",
      "Epoch 56/500\n",
      "404/404 [==============================] - 0s 428us/sample - loss: 20.1537 - val_loss: 29.8935\n",
      "Epoch 57/500\n",
      "404/404 [==============================] - 0s 410us/sample - loss: 34.9878 - val_loss: 35.7034\n",
      "Epoch 58/500\n",
      "404/404 [==============================] - 0s 544us/sample - loss: 18.0580 - val_loss: 46.6381\n",
      "Epoch 59/500\n",
      "404/404 [==============================] - 0s 519us/sample - loss: 22.1255 - val_loss: 30.7520\n",
      "Epoch 60/500\n",
      "404/404 [==============================] - 0s 460us/sample - loss: 20.1802 - val_loss: 32.1423\n",
      "Epoch 61/500\n",
      "404/404 [==============================] - 0s 530us/sample - loss: 21.6455 - val_loss: 31.3954\n",
      "Epoch 62/500\n",
      "404/404 [==============================] - 0s 387us/sample - loss: 26.6945 - val_loss: 30.0174\n",
      "Epoch 63/500\n",
      "404/404 [==============================] - 0s 409us/sample - loss: 18.4146 - val_loss: 28.5735\n",
      "Epoch 64/500\n",
      "404/404 [==============================] - 0s 459us/sample - loss: 17.4828 - val_loss: 27.5143\n",
      "Epoch 65/500\n",
      "404/404 [==============================] - 0s 597us/sample - loss: 15.9922 - val_loss: 27.6064\n",
      "Epoch 66/500\n",
      "404/404 [==============================] - 0s 533us/sample - loss: 21.5911 - val_loss: 29.7999\n",
      "Epoch 67/500\n",
      "404/404 [==============================] - 0s 380us/sample - loss: 20.3382 - val_loss: 37.3314\n",
      "Epoch 68/500\n",
      "404/404 [==============================] - 0s 379us/sample - loss: 15.3293 - val_loss: 30.3661\n",
      "Epoch 69/500\n",
      "404/404 [==============================] - 0s 376us/sample - loss: 14.7065 - val_loss: 27.5167\n",
      "Epoch 70/500\n",
      "404/404 [==============================] - 0s 422us/sample - loss: 13.8043 - val_loss: 27.0628\n",
      "Epoch 71/500\n",
      "404/404 [==============================] - 0s 565us/sample - loss: 17.1834 - val_loss: 27.9137\n",
      "Epoch 72/500\n",
      "404/404 [==============================] - 0s 547us/sample - loss: 16.2164 - val_loss: 27.0763\n",
      "Epoch 73/500\n",
      "404/404 [==============================] - 0s 514us/sample - loss: 13.5473 - val_loss: 26.5319\n",
      "Epoch 74/500\n",
      "404/404 [==============================] - 0s 389us/sample - loss: 15.7028 - val_loss: 26.6313\n",
      "Epoch 75/500\n",
      "404/404 [==============================] - 0s 380us/sample - loss: 13.4437 - val_loss: 34.6776\n",
      "Epoch 76/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 378us/sample - loss: 17.1436 - val_loss: 28.4748\n",
      "Epoch 77/500\n",
      "404/404 [==============================] - 0s 378us/sample - loss: 17.4389 - val_loss: 30.5781\n",
      "Epoch 78/500\n",
      "404/404 [==============================] - 0s 412us/sample - loss: 14.7337 - val_loss: 29.8024\n",
      "Epoch 79/500\n",
      "404/404 [==============================] - 0s 520us/sample - loss: 13.2427 - val_loss: 25.5597\n",
      "Epoch 80/500\n",
      "404/404 [==============================] - 0s 436us/sample - loss: 16.0447 - val_loss: 33.4879\n",
      "Epoch 81/500\n",
      "404/404 [==============================] - 0s 376us/sample - loss: 16.3480 - val_loss: 26.2011\n",
      "Epoch 82/500\n",
      "404/404 [==============================] - 0s 368us/sample - loss: 12.6436 - val_loss: 25.4413\n",
      "Epoch 83/500\n",
      "404/404 [==============================] - 0s 396us/sample - loss: 13.7213 - val_loss: 35.2049\n",
      "Epoch 84/500\n",
      "404/404 [==============================] - 0s 389us/sample - loss: 13.1564 - val_loss: 32.1433\n",
      "Epoch 85/500\n",
      "404/404 [==============================] - 0s 396us/sample - loss: 14.1181 - val_loss: 26.7625\n",
      "Epoch 86/500\n",
      "404/404 [==============================] - 0s 508us/sample - loss: 11.9652 - val_loss: 26.7219\n",
      "Epoch 87/500\n",
      "404/404 [==============================] - 0s 493us/sample - loss: 12.8662 - val_loss: 29.4650\n",
      "Epoch 88/500\n",
      "404/404 [==============================] - 0s 390us/sample - loss: 12.5219 - val_loss: 28.3669\n",
      "Epoch 89/500\n",
      "404/404 [==============================] - 0s 375us/sample - loss: 11.8356 - val_loss: 31.2083\n",
      "Epoch 90/500\n",
      "404/404 [==============================] - 0s 377us/sample - loss: 13.5254 - val_loss: 38.2586\n",
      "Epoch 91/500\n",
      "404/404 [==============================] - 0s 386us/sample - loss: 15.4526 - val_loss: 27.3005\n",
      "Epoch 92/500\n",
      "404/404 [==============================] - 0s 368us/sample - loss: 11.5197 - val_loss: 26.5072\n",
      "Epoch 93/500\n",
      "404/404 [==============================] - 0s 507us/sample - loss: 13.0700 - val_loss: 35.2616\n",
      "Epoch 94/500\n",
      "404/404 [==============================] - 0s 514us/sample - loss: 14.0549 - val_loss: 26.6785\n",
      "Epoch 95/500\n",
      "404/404 [==============================] - 0s 366us/sample - loss: 11.7987 - val_loss: 26.4167\n",
      "Epoch 96/500\n",
      "404/404 [==============================] - 0s 380us/sample - loss: 12.5766 - val_loss: 26.0244\n",
      "Epoch 97/500\n",
      "404/404 [==============================] - 0s 380us/sample - loss: 12.6296 - val_loss: 29.0225\n",
      "Epoch 98/500\n",
      "404/404 [==============================] - 0s 374us/sample - loss: 11.8512 - val_loss: 26.2080\n",
      "Epoch 99/500\n",
      "404/404 [==============================] - 0s 383us/sample - loss: 11.8910 - val_loss: 25.4147\n",
      "Epoch 100/500\n",
      "404/404 [==============================] - 0s 439us/sample - loss: 11.2220 - val_loss: 26.2578\n",
      "Epoch 101/500\n",
      "404/404 [==============================] - 0s 474us/sample - loss: 12.7790 - val_loss: 30.1557\n",
      "Epoch 102/500\n",
      "404/404 [==============================] - 0s 497us/sample - loss: 12.6701 - val_loss: 25.6948\n",
      "Epoch 103/500\n",
      "404/404 [==============================] - 0s 396us/sample - loss: 12.6382 - val_loss: 28.0730\n",
      "Epoch 104/500\n",
      "404/404 [==============================] - 0s 363us/sample - loss: 11.9723 - val_loss: 24.8225\n",
      "Epoch 105/500\n",
      "404/404 [==============================] - 0s 388us/sample - loss: 11.2256 - val_loss: 24.4511\n",
      "Epoch 106/500\n",
      "404/404 [==============================] - 0s 371us/sample - loss: 11.7257 - val_loss: 25.4199\n",
      "Epoch 107/500\n",
      "404/404 [==============================] - 0s 407us/sample - loss: 12.9431 - val_loss: 26.0231\n",
      "Epoch 108/500\n",
      "404/404 [==============================] - 0s 515us/sample - loss: 11.1787 - val_loss: 28.4909\n",
      "Epoch 109/500\n",
      "404/404 [==============================] - 0s 397us/sample - loss: 11.1954 - val_loss: 28.4246\n",
      "Epoch 110/500\n",
      "404/404 [==============================] - 0s 381us/sample - loss: 10.9483 - val_loss: 25.0363\n",
      "Epoch 111/500\n",
      "404/404 [==============================] - 0s 370us/sample - loss: 12.1342 - val_loss: 25.2304\n",
      "Epoch 112/500\n",
      "404/404 [==============================] - 0s 369us/sample - loss: 11.8298 - val_loss: 24.2539\n",
      "Epoch 113/500\n",
      "404/404 [==============================] - 0s 374us/sample - loss: 10.9639 - val_loss: 25.0366\n",
      "Epoch 114/500\n",
      "404/404 [==============================] - 0s 410us/sample - loss: 11.2612 - val_loss: 28.8106\n",
      "Epoch 115/500\n",
      "404/404 [==============================] - 0s 522us/sample - loss: 11.7911 - val_loss: 25.6597\n",
      "Epoch 116/500\n",
      "404/404 [==============================] - 0s 371us/sample - loss: 11.3023 - val_loss: 25.5754\n",
      "Epoch 117/500\n",
      "404/404 [==============================] - 0s 378us/sample - loss: 11.2654 - val_loss: 25.9942\n",
      "Epoch 118/500\n",
      "404/404 [==============================] - 0s 375us/sample - loss: 10.6084 - val_loss: 24.4340\n",
      "Epoch 119/500\n",
      "404/404 [==============================] - 0s 383us/sample - loss: 12.3179 - val_loss: 24.9783\n",
      "Epoch 120/500\n",
      "404/404 [==============================] - 0s 375us/sample - loss: 10.4672 - val_loss: 24.5084\n",
      "Epoch 121/500\n",
      "404/404 [==============================] - 0s 418us/sample - loss: 12.0533 - val_loss: 24.6077\n",
      "Epoch 122/500\n",
      "404/404 [==============================] - 0s 504us/sample - loss: 11.5366 - val_loss: 25.8417\n",
      "Epoch 123/500\n",
      "404/404 [==============================] - 0s 469us/sample - loss: 11.0575 - val_loss: 25.5309\n",
      "Epoch 124/500\n",
      "404/404 [==============================] - 0s 397us/sample - loss: 10.6374 - val_loss: 24.7274\n",
      "Epoch 125/500\n",
      "404/404 [==============================] - 0s 373us/sample - loss: 10.3270 - val_loss: 24.5665\n",
      "Epoch 126/500\n",
      "404/404 [==============================] - 0s 372us/sample - loss: 11.5932 - val_loss: 27.2630\n",
      "Epoch 127/500\n",
      "404/404 [==============================] - 0s 376us/sample - loss: 10.5492 - val_loss: 23.2413\n",
      "Epoch 128/500\n",
      "404/404 [==============================] - 0s 363us/sample - loss: 10.9206 - val_loss: 25.4057\n",
      "Epoch 129/500\n",
      "404/404 [==============================] - 0s 448us/sample - loss: 11.4457 - val_loss: 33.6913\n",
      "Epoch 130/500\n",
      "404/404 [==============================] - 0s 512us/sample - loss: 10.4733 - val_loss: 24.3544\n",
      "Epoch 131/500\n",
      "404/404 [==============================] - 0s 380us/sample - loss: 10.3560 - val_loss: 24.3647\n",
      "Epoch 132/500\n",
      "404/404 [==============================] - 0s 373us/sample - loss: 15.3435 - val_loss: 22.4033\n",
      "Epoch 133/500\n",
      "404/404 [==============================] - 0s 370us/sample - loss: 10.9190 - val_loss: 23.7257\n",
      "Epoch 134/500\n",
      "404/404 [==============================] - 0s 376us/sample - loss: 9.7480 - val_loss: 24.0885\n",
      "Epoch 135/500\n",
      "404/404 [==============================] - 0s 374us/sample - loss: 9.7234 - val_loss: 22.0148\n",
      "Epoch 136/500\n",
      "404/404 [==============================] - 0s 412us/sample - loss: 11.7533 - val_loss: 24.0424\n",
      "Epoch 137/500\n",
      "404/404 [==============================] - 0s 516us/sample - loss: 11.4479 - val_loss: 26.7764\n",
      "Epoch 138/500\n",
      "404/404 [==============================] - 0s 475us/sample - loss: 10.5779 - val_loss: 24.9385\n",
      "Epoch 139/500\n",
      "404/404 [==============================] - 0s 473us/sample - loss: 9.3881 - val_loss: 23.3664\n",
      "Epoch 140/500\n",
      "404/404 [==============================] - 0s 395us/sample - loss: 10.2793 - val_loss: 23.7057\n",
      "Epoch 141/500\n",
      "404/404 [==============================] - 0s 377us/sample - loss: 10.2628 - val_loss: 25.8670\n",
      "Epoch 142/500\n",
      "404/404 [==============================] - 0s 375us/sample - loss: 10.9876 - val_loss: 22.1975\n",
      "Epoch 143/500\n",
      "404/404 [==============================] - 0s 375us/sample - loss: 9.2679 - val_loss: 22.2563\n",
      "Epoch 144/500\n",
      "404/404 [==============================] - 0s 427us/sample - loss: 10.9793 - val_loss: 21.7970\n",
      "Epoch 145/500\n",
      "404/404 [==============================] - 0s 509us/sample - loss: 10.4702 - val_loss: 27.6950\n",
      "Epoch 146/500\n",
      "404/404 [==============================] - 0s 418us/sample - loss: 10.5007 - val_loss: 23.1412\n",
      "Epoch 147/500\n",
      "404/404 [==============================] - 0s 367us/sample - loss: 10.7635 - val_loss: 28.5226\n",
      "Epoch 148/500\n",
      "404/404 [==============================] - 0s 503us/sample - loss: 9.7475 - val_loss: 25.8612\n",
      "Epoch 149/500\n",
      "404/404 [==============================] - 0s 827us/sample - loss: 12.7114 - val_loss: 24.2655\n",
      "Epoch 150/500\n",
      "404/404 [==============================] - 0s 911us/sample - loss: 9.9322 - val_loss: 23.1124\n",
      "Epoch 151/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 800us/sample - loss: 9.5226 - val_loss: 25.5639\n",
      "Epoch 152/500\n",
      "404/404 [==============================] - 0s 498us/sample - loss: 10.1381 - val_loss: 22.3398\n",
      "Epoch 153/500\n",
      "404/404 [==============================] - 0s 459us/sample - loss: 10.3234 - val_loss: 21.6050\n",
      "Epoch 154/500\n",
      "404/404 [==============================] - 0s 386us/sample - loss: 9.4124 - val_loss: 23.3874\n",
      "Epoch 155/500\n",
      "404/404 [==============================] - 0s 465us/sample - loss: 9.3222 - val_loss: 26.0552\n",
      "Epoch 156/500\n",
      "404/404 [==============================] - 0s 385us/sample - loss: 10.5077 - val_loss: 22.4317\n",
      "Epoch 157/500\n",
      "404/404 [==============================] - 0s 366us/sample - loss: 9.1474 - val_loss: 26.3787\n",
      "Epoch 158/500\n",
      "404/404 [==============================] - 0s 423us/sample - loss: 9.2884 - val_loss: 22.2049\n",
      "Epoch 159/500\n",
      "404/404 [==============================] - 0s 640us/sample - loss: 10.2649 - val_loss: 24.1468\n",
      "Epoch 160/500\n",
      "404/404 [==============================] - 0s 817us/sample - loss: 9.6404 - val_loss: 25.7029\n",
      "Epoch 161/500\n",
      "404/404 [==============================] - 0s 678us/sample - loss: 9.5424 - val_loss: 23.8348\n",
      "Epoch 162/500\n",
      "404/404 [==============================] - 0s 520us/sample - loss: 8.6661 - val_loss: 23.1115\n",
      "Epoch 163/500\n",
      "404/404 [==============================] - 0s 470us/sample - loss: 9.8423 - val_loss: 22.9798\n",
      "Epoch 164/500\n",
      "404/404 [==============================] - 0s 488us/sample - loss: 9.0498 - val_loss: 23.5636\n",
      "Epoch 165/500\n",
      "404/404 [==============================] - 0s 809us/sample - loss: 10.2101 - val_loss: 20.7516\n",
      "Epoch 166/500\n",
      "404/404 [==============================] - 0s 955us/sample - loss: 9.1866 - val_loss: 26.6065\n",
      "Epoch 167/500\n",
      "404/404 [==============================] - 0s 943us/sample - loss: 9.0512 - val_loss: 28.0892\n",
      "Epoch 168/500\n",
      "404/404 [==============================] - 0s 922us/sample - loss: 9.4516 - val_loss: 24.1115\n",
      "Epoch 169/500\n",
      "404/404 [==============================] - 0s 682us/sample - loss: 8.9857 - val_loss: 22.1187\n",
      "Epoch 170/500\n",
      "404/404 [==============================] - 0s 553us/sample - loss: 9.1058 - val_loss: 21.0657\n",
      "Epoch 171/500\n",
      "404/404 [==============================] - 0s 489us/sample - loss: 8.7548 - val_loss: 22.3653\n",
      "Epoch 172/500\n",
      "404/404 [==============================] - 0s 474us/sample - loss: 11.4640 - val_loss: 20.4483\n",
      "Epoch 173/500\n",
      "404/404 [==============================] - 0s 393us/sample - loss: 10.0342 - val_loss: 22.2606\n",
      "Epoch 174/500\n",
      "404/404 [==============================] - 0s 511us/sample - loss: 8.7189 - val_loss: 23.0971\n",
      "Epoch 175/500\n",
      "404/404 [==============================] - 0s 401us/sample - loss: 9.7327 - val_loss: 20.9449\n",
      "Epoch 176/500\n",
      "404/404 [==============================] - 0s 696us/sample - loss: 9.5295 - val_loss: 28.4854\n",
      "Epoch 177/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 9.8640 - val_loss: 23.0164\n",
      "Epoch 178/500\n",
      "404/404 [==============================] - 0s 928us/sample - loss: 8.3508 - val_loss: 21.6020\n",
      "Epoch 179/500\n",
      "404/404 [==============================] - 0s 977us/sample - loss: 8.6782 - val_loss: 21.6425\n",
      "Epoch 180/500\n",
      "404/404 [==============================] - 0s 893us/sample - loss: 9.4541 - val_loss: 21.7526\n",
      "Epoch 181/500\n",
      "404/404 [==============================] - 0s 850us/sample - loss: 8.6334 - val_loss: 22.1034\n",
      "Epoch 182/500\n",
      "404/404 [==============================] - 0s 782us/sample - loss: 9.6127 - val_loss: 24.6123\n",
      "Epoch 183/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 10.5185 - val_loss: 21.1428\n",
      "Epoch 184/500\n",
      "404/404 [==============================] - ETA: 0s - loss: 8.935 - 0s 870us/sample - loss: 8.4539 - val_loss: 21.3102\n",
      "Epoch 185/500\n",
      "404/404 [==============================] - 0s 777us/sample - loss: 8.5276 - val_loss: 22.3189\n",
      "Epoch 186/500\n",
      "404/404 [==============================] - 0s 664us/sample - loss: 8.7931 - val_loss: 22.4406\n",
      "Epoch 187/500\n",
      "404/404 [==============================] - 0s 808us/sample - loss: 9.2270 - val_loss: 21.5790\n",
      "Epoch 188/500\n",
      "404/404 [==============================] - 0s 749us/sample - loss: 9.1701 - val_loss: 24.1398\n",
      "Epoch 189/500\n",
      "404/404 [==============================] - 0s 790us/sample - loss: 9.8616 - val_loss: 23.3812\n",
      "Epoch 190/500\n",
      "404/404 [==============================] - 0s 745us/sample - loss: 8.4539 - val_loss: 29.0810\n",
      "Epoch 191/500\n",
      "404/404 [==============================] - 0s 730us/sample - loss: 9.7900 - val_loss: 23.6368\n",
      "Epoch 192/500\n",
      "404/404 [==============================] - 0s 967us/sample - loss: 8.3508 - val_loss: 23.1487\n",
      "Epoch 193/500\n",
      "404/404 [==============================] - 0s 900us/sample - loss: 8.6225 - val_loss: 22.0738\n",
      "Epoch 194/500\n",
      "404/404 [==============================] - 0s 789us/sample - loss: 8.9047 - val_loss: 22.3941\n",
      "Epoch 195/500\n",
      "404/404 [==============================] - 0s 805us/sample - loss: 8.5821 - val_loss: 29.5284\n",
      "Epoch 196/500\n",
      "404/404 [==============================] - 0s 929us/sample - loss: 10.4434 - val_loss: 21.3414\n",
      "Epoch 197/500\n",
      "404/404 [==============================] - 0s 801us/sample - loss: 10.0495 - val_loss: 22.9927\n",
      "Epoch 198/500\n",
      "404/404 [==============================] - 0s 835us/sample - loss: 8.3549 - val_loss: 24.1612\n",
      "Epoch 199/500\n",
      "404/404 [==============================] - 0s 899us/sample - loss: 8.0804 - val_loss: 22.0230\n",
      "Epoch 200/500\n",
      "404/404 [==============================] - 0s 852us/sample - loss: 8.5719 - val_loss: 22.3539\n",
      "Epoch 201/500\n",
      "404/404 [==============================] - 0s 901us/sample - loss: 8.1056 - val_loss: 26.0130\n",
      "Epoch 202/500\n",
      "404/404 [==============================] - 0s 903us/sample - loss: 8.5247 - val_loss: 24.2456\n",
      "Epoch 203/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 8.9910 - val_loss: 22.4646\n",
      "Epoch 204/500\n",
      "404/404 [==============================] - 0s 815us/sample - loss: 9.6222 - val_loss: 23.2019\n",
      "Epoch 205/500\n",
      "404/404 [==============================] - 0s 807us/sample - loss: 8.2928 - val_loss: 21.4649\n",
      "Epoch 206/500\n",
      "404/404 [==============================] - 0s 776us/sample - loss: 8.8804 - val_loss: 21.8133\n",
      "Epoch 207/500\n",
      "404/404 [==============================] - 0s 780us/sample - loss: 8.5206 - val_loss: 22.1168\n",
      "Epoch 208/500\n",
      "404/404 [==============================] - 0s 951us/sample - loss: 9.5084 - val_loss: 35.4517\n",
      "Epoch 209/500\n",
      "404/404 [==============================] - 0s 944us/sample - loss: 11.2865 - val_loss: 21.7362\n",
      "Epoch 210/500\n",
      "404/404 [==============================] - 0s 851us/sample - loss: 8.8415 - val_loss: 22.8152\n",
      "Epoch 211/500\n",
      "404/404 [==============================] - 0s 967us/sample - loss: 8.3863 - val_loss: 21.0939\n",
      "Epoch 212/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 7.7877 - val_loss: 23.6900\n",
      "Epoch 213/500\n",
      "404/404 [==============================] - 0s 745us/sample - loss: 7.7233 - val_loss: 22.3165\n",
      "Epoch 214/500\n",
      "404/404 [==============================] - 0s 709us/sample - loss: 7.9786 - val_loss: 21.9306\n",
      "Epoch 215/500\n",
      "404/404 [==============================] - ETA: 0s - loss: 8.385 - 0s 798us/sample - loss: 8.1070 - val_loss: 21.6641\n",
      "Epoch 216/500\n",
      "404/404 [==============================] - 0s 879us/sample - loss: 7.9279 - val_loss: 22.3087\n",
      "Epoch 217/500\n",
      "404/404 [==============================] - 0s 808us/sample - loss: 8.0829 - val_loss: 21.3284\n",
      "Epoch 218/500\n",
      "404/404 [==============================] - 0s 825us/sample - loss: 8.1623 - val_loss: 22.6180\n",
      "Epoch 219/500\n",
      "404/404 [==============================] - 0s 851us/sample - loss: 7.6859 - val_loss: 23.0361\n",
      "Epoch 220/500\n",
      "404/404 [==============================] - 0s 800us/sample - loss: 8.7368 - val_loss: 22.1919\n",
      "Epoch 221/500\n",
      "404/404 [==============================] - 0s 833us/sample - loss: 8.0058 - val_loss: 26.3741\n",
      "Epoch 222/500\n",
      "404/404 [==============================] - 0s 934us/sample - loss: 8.0916 - val_loss: 23.8216\n",
      "Epoch 223/500\n",
      "404/404 [==============================] - 0s 782us/sample - loss: 7.7662 - val_loss: 21.3030\n",
      "Epoch 224/500\n",
      "404/404 [==============================] - 0s 780us/sample - loss: 7.6954 - val_loss: 19.1216\n",
      "Epoch 225/500\n",
      "404/404 [==============================] - 0s 841us/sample - loss: 8.2018 - val_loss: 21.6998\n",
      "Epoch 226/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 787us/sample - loss: 7.4712 - val_loss: 21.9276\n",
      "Epoch 227/500\n",
      "404/404 [==============================] - 0s 776us/sample - loss: 7.7306 - val_loss: 21.7934\n",
      "Epoch 228/500\n",
      "404/404 [==============================] - 0s 740us/sample - loss: 8.6329 - val_loss: 24.9577\n",
      "Epoch 229/500\n",
      "404/404 [==============================] - 0s 737us/sample - loss: 9.2104 - val_loss: 21.9471\n",
      "Epoch 230/500\n",
      "404/404 [==============================] - 0s 813us/sample - loss: 7.7733 - val_loss: 21.5499\n",
      "Epoch 231/500\n",
      "404/404 [==============================] - 0s 768us/sample - loss: 8.7643 - val_loss: 23.2484\n",
      "Epoch 232/500\n",
      "404/404 [==============================] - 0s 792us/sample - loss: 7.3197 - val_loss: 21.4692\n",
      "Epoch 233/500\n",
      "404/404 [==============================] - 0s 751us/sample - loss: 7.5488 - val_loss: 21.1310\n",
      "Epoch 234/500\n",
      "404/404 [==============================] - 0s 794us/sample - loss: 7.4067 - val_loss: 21.2349\n",
      "Epoch 235/500\n",
      "404/404 [==============================] - 0s 947us/sample - loss: 7.6875 - val_loss: 24.4881\n",
      "Epoch 236/500\n",
      "404/404 [==============================] - 0s 897us/sample - loss: 8.1526 - val_loss: 19.1106\n",
      "Epoch 237/500\n",
      "404/404 [==============================] - 0s 775us/sample - loss: 7.7029 - val_loss: 22.7276\n",
      "Epoch 238/500\n",
      "404/404 [==============================] - 0s 751us/sample - loss: 7.6080 - val_loss: 23.0892\n",
      "Epoch 239/500\n",
      "404/404 [==============================] - 0s 836us/sample - loss: 7.8499 - val_loss: 23.7028\n",
      "Epoch 240/500\n",
      "404/404 [==============================] - 0s 830us/sample - loss: 7.9653 - val_loss: 21.0969\n",
      "Epoch 241/500\n",
      "404/404 [==============================] - 0s 745us/sample - loss: 7.5347 - val_loss: 22.0309\n",
      "Epoch 242/500\n",
      "404/404 [==============================] - 0s 743us/sample - loss: 8.1824 - val_loss: 24.1486\n",
      "Epoch 243/500\n",
      "404/404 [==============================] - 0s 787us/sample - loss: 7.2325 - val_loss: 21.1168\n",
      "Epoch 244/500\n",
      "404/404 [==============================] - 0s 857us/sample - loss: 8.6927 - val_loss: 23.9726\n",
      "Epoch 245/500\n",
      "404/404 [==============================] - 0s 790us/sample - loss: 7.7510 - val_loss: 22.1569\n",
      "Epoch 246/500\n",
      "404/404 [==============================] - 0s 776us/sample - loss: 7.1293 - val_loss: 22.2149\n",
      "Epoch 247/500\n",
      "404/404 [==============================] - 0s 769us/sample - loss: 7.3175 - val_loss: 24.9585\n",
      "Epoch 248/500\n",
      "404/404 [==============================] - 0s 761us/sample - loss: 9.6911 - val_loss: 19.8904\n",
      "Epoch 249/500\n",
      "404/404 [==============================] - 0s 716us/sample - loss: 7.9349 - val_loss: 21.6796\n",
      "Epoch 250/500\n",
      "404/404 [==============================] - 0s 779us/sample - loss: 7.1024 - val_loss: 20.5967\n",
      "Epoch 251/500\n",
      "404/404 [==============================] - 0s 881us/sample - loss: 7.0353 - val_loss: 23.1703\n",
      "Epoch 252/500\n",
      "404/404 [==============================] - 0s 758us/sample - loss: 7.5126 - val_loss: 21.9102\n",
      "Epoch 253/500\n",
      "404/404 [==============================] - 0s 718us/sample - loss: 7.5032 - val_loss: 26.0688\n",
      "Epoch 254/500\n",
      "404/404 [==============================] - 0s 781us/sample - loss: 7.1738 - val_loss: 22.4551\n",
      "Epoch 255/500\n",
      "404/404 [==============================] - 0s 866us/sample - loss: 8.0815 - val_loss: 20.4145\n",
      "Epoch 256/500\n",
      "404/404 [==============================] - 0s 743us/sample - loss: 7.3044 - val_loss: 24.8230\n",
      "Epoch 257/500\n",
      "404/404 [==============================] - 0s 758us/sample - loss: 7.3333 - val_loss: 20.5675\n",
      "Epoch 258/500\n",
      "404/404 [==============================] - 0s 747us/sample - loss: 8.6810 - val_loss: 20.9737\n",
      "Epoch 259/500\n",
      "404/404 [==============================] - 0s 799us/sample - loss: 7.0127 - val_loss: 21.9404\n",
      "Epoch 260/500\n",
      "404/404 [==============================] - 0s 795us/sample - loss: 7.7377 - val_loss: 21.8575\n",
      "Epoch 261/500\n",
      "404/404 [==============================] - 0s 772us/sample - loss: 7.8170 - val_loss: 23.3148\n",
      "Epoch 262/500\n",
      "404/404 [==============================] - 0s 735us/sample - loss: 7.2749 - val_loss: 19.0435\n",
      "Epoch 263/500\n",
      "404/404 [==============================] - 0s 939us/sample - loss: 7.5065 - val_loss: 21.7175\n",
      "Epoch 264/500\n",
      "404/404 [==============================] - 0s 778us/sample - loss: 7.6546 - val_loss: 23.1756\n",
      "Epoch 265/500\n",
      "404/404 [==============================] - 0s 757us/sample - loss: 7.9706 - val_loss: 26.8960\n",
      "Epoch 266/500\n",
      "404/404 [==============================] - 0s 897us/sample - loss: 10.0124 - val_loss: 19.9531\n",
      "Epoch 267/500\n",
      "404/404 [==============================] - 0s 970us/sample - loss: 8.7287 - val_loss: 23.1434\n",
      "Epoch 268/500\n",
      "404/404 [==============================] - 0s 837us/sample - loss: 6.7869 - val_loss: 21.6152\n",
      "Epoch 269/500\n",
      "404/404 [==============================] - 0s 789us/sample - loss: 7.2594 - val_loss: 24.9269\n",
      "Epoch 270/500\n",
      "404/404 [==============================] - 0s 677us/sample - loss: 7.1181 - val_loss: 19.5873\n",
      "Epoch 271/500\n",
      "404/404 [==============================] - 0s 826us/sample - loss: 6.6668 - val_loss: 25.4363\n",
      "Epoch 272/500\n",
      "404/404 [==============================] - 0s 801us/sample - loss: 7.2355 - val_loss: 23.8294\n",
      "Epoch 273/500\n",
      "404/404 [==============================] - 0s 861us/sample - loss: 6.4539 - val_loss: 20.8103\n",
      "Epoch 274/500\n",
      "404/404 [==============================] - 0s 839us/sample - loss: 7.1033 - val_loss: 19.4659\n",
      "Epoch 275/500\n",
      "404/404 [==============================] - 0s 810us/sample - loss: 7.6090 - val_loss: 22.3309\n",
      "Epoch 276/500\n",
      "404/404 [==============================] - 0s 904us/sample - loss: 7.2440 - val_loss: 22.8184\n",
      "Epoch 277/500\n",
      "404/404 [==============================] - 0s 864us/sample - loss: 6.6498 - val_loss: 24.7010\n",
      "Epoch 278/500\n",
      "404/404 [==============================] - 0s 852us/sample - loss: 7.1126 - val_loss: 21.3375\n",
      "Epoch 279/500\n",
      "404/404 [==============================] - 0s 859us/sample - loss: 6.6731 - val_loss: 22.4606\n",
      "Epoch 280/500\n",
      "404/404 [==============================] - 0s 787us/sample - loss: 7.1623 - val_loss: 19.8129\n",
      "Epoch 281/500\n",
      "404/404 [==============================] - 0s 538us/sample - loss: 6.4524 - val_loss: 19.5217\n",
      "Epoch 282/500\n",
      "404/404 [==============================] - 0s 870us/sample - loss: 7.9678 - val_loss: 19.4476\n",
      "Epoch 283/500\n",
      "404/404 [==============================] - 0s 693us/sample - loss: 6.7271 - val_loss: 21.1156\n",
      "Epoch 284/500\n",
      "404/404 [==============================] - 0s 449us/sample - loss: 6.8138 - val_loss: 20.4851\n",
      "Epoch 285/500\n",
      "404/404 [==============================] - 0s 376us/sample - loss: 7.0003 - val_loss: 23.6970\n",
      "Epoch 286/500\n",
      "404/404 [==============================] - 0s 379us/sample - loss: 6.7137 - val_loss: 21.2356\n",
      "Epoch 287/500\n",
      "404/404 [==============================] - 0s 516us/sample - loss: 6.5996 - val_loss: 23.1624\n",
      "Epoch 288/500\n",
      "404/404 [==============================] - 0s 570us/sample - loss: 7.6872 - val_loss: 21.3063\n",
      "Epoch 289/500\n",
      "404/404 [==============================] - 0s 414us/sample - loss: 7.4513 - val_loss: 23.6518\n",
      "Epoch 290/500\n",
      "404/404 [==============================] - 0s 372us/sample - loss: 6.3752 - val_loss: 21.4653\n",
      "Epoch 291/500\n",
      "404/404 [==============================] - 0s 373us/sample - loss: 6.2387 - val_loss: 19.7222\n",
      "Epoch 292/500\n",
      "404/404 [==============================] - 0s 376us/sample - loss: 7.5257 - val_loss: 19.6297\n",
      "Epoch 293/500\n",
      "404/404 [==============================] - 0s 429us/sample - loss: 6.5380 - val_loss: 22.7352\n",
      "Epoch 294/500\n",
      "404/404 [==============================] - 0s 506us/sample - loss: 6.2668 - val_loss: 22.4902\n",
      "Epoch 295/500\n",
      "404/404 [==============================] - 0s 387us/sample - loss: 6.6185 - val_loss: 20.6988\n",
      "Epoch 296/500\n",
      "404/404 [==============================] - 0s 387us/sample - loss: 6.2516 - val_loss: 23.7061\n",
      "Epoch 297/500\n",
      "404/404 [==============================] - 0s 391us/sample - loss: 6.7989 - val_loss: 20.6335\n",
      "Epoch 298/500\n",
      "404/404 [==============================] - 0s 380us/sample - loss: 6.6243 - val_loss: 18.5158\n",
      "Epoch 299/500\n",
      "404/404 [==============================] - 0s 644us/sample - loss: 5.9272 - val_loss: 20.0418\n",
      "Epoch 300/500\n",
      "404/404 [==============================] - 0s 672us/sample - loss: 5.8862 - val_loss: 20.6297\n",
      "Epoch 301/500\n",
      "404/404 [==============================] - 0s 790us/sample - loss: 6.3491 - val_loss: 23.2676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302/500\n",
      "404/404 [==============================] - 0s 973us/sample - loss: 6.3805 - val_loss: 22.8579\n",
      "Epoch 303/500\n",
      "404/404 [==============================] - 0s 776us/sample - loss: 6.3292 - val_loss: 19.6741\n",
      "Epoch 304/500\n",
      "404/404 [==============================] - 0s 782us/sample - loss: 6.5909 - val_loss: 20.7616\n",
      "Epoch 305/500\n",
      "404/404 [==============================] - 0s 879us/sample - loss: 6.2895 - val_loss: 20.2837\n",
      "Epoch 306/500\n",
      "404/404 [==============================] - 0s 851us/sample - loss: 5.8909 - val_loss: 21.6537\n",
      "Epoch 307/500\n",
      "404/404 [==============================] - 0s 860us/sample - loss: 6.9379 - val_loss: 23.4777\n",
      "Epoch 308/500\n",
      "404/404 [==============================] - 0s 790us/sample - loss: 6.2643 - val_loss: 21.1376\n",
      "Epoch 309/500\n",
      "404/404 [==============================] - 0s 861us/sample - loss: 5.7965 - val_loss: 20.3755\n",
      "Epoch 310/500\n",
      "404/404 [==============================] - 0s 773us/sample - loss: 6.0141 - val_loss: 19.6580\n",
      "Epoch 311/500\n",
      "404/404 [==============================] - 0s 879us/sample - loss: 6.9356 - val_loss: 19.2105\n",
      "Epoch 312/500\n",
      "404/404 [==============================] - 0s 775us/sample - loss: 6.2676 - val_loss: 21.0517\n",
      "Epoch 313/500\n",
      "404/404 [==============================] - 0s 760us/sample - loss: 7.2204 - val_loss: 20.2263\n",
      "Epoch 314/500\n",
      "404/404 [==============================] - 0s 721us/sample - loss: 5.9342 - val_loss: 18.8021\n",
      "Epoch 315/500\n",
      "404/404 [==============================] - 0s 835us/sample - loss: 5.8448 - val_loss: 21.7626\n",
      "Epoch 316/500\n",
      "404/404 [==============================] - 0s 845us/sample - loss: 6.8475 - val_loss: 20.0497\n",
      "Epoch 317/500\n",
      "404/404 [==============================] - 0s 778us/sample - loss: 5.9012 - val_loss: 19.6622\n",
      "Epoch 318/500\n",
      "404/404 [==============================] - 0s 677us/sample - loss: 6.5193 - val_loss: 21.5330\n",
      "Epoch 319/500\n",
      "404/404 [==============================] - 0s 730us/sample - loss: 6.0372 - val_loss: 24.0386\n",
      "Epoch 320/500\n",
      "404/404 [==============================] - 0s 831us/sample - loss: 5.7773 - val_loss: 21.8557\n",
      "Epoch 321/500\n",
      "404/404 [==============================] - 0s 842us/sample - loss: 5.6842 - val_loss: 22.8404\n",
      "Epoch 322/500\n",
      "404/404 [==============================] - 0s 746us/sample - loss: 6.2437 - val_loss: 20.2557\n",
      "Epoch 323/500\n",
      "404/404 [==============================] - 0s 863us/sample - loss: 6.0508 - val_loss: 19.1866\n",
      "Epoch 324/500\n",
      "404/404 [==============================] - 0s 777us/sample - loss: 5.6168 - val_loss: 19.7085\n",
      "Epoch 325/500\n",
      "404/404 [==============================] - 0s 765us/sample - loss: 7.3309 - val_loss: 20.7408\n",
      "Epoch 326/500\n",
      "404/404 [==============================] - 0s 758us/sample - loss: 6.4676 - val_loss: 23.6143\n",
      "Epoch 327/500\n",
      "404/404 [==============================] - 0s 820us/sample - loss: 6.4506 - val_loss: 21.6682\n",
      "Epoch 328/500\n",
      "404/404 [==============================] - 0s 826us/sample - loss: 5.6944 - val_loss: 20.9208\n",
      "Epoch 329/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 5.5361 - val_loss: 20.8275\n",
      "Epoch 330/500\n",
      "404/404 [==============================] - 0s 814us/sample - loss: 5.7001 - val_loss: 19.7131\n",
      "Epoch 331/500\n",
      "404/404 [==============================] - 0s 778us/sample - loss: 5.4830 - val_loss: 19.9020\n",
      "Epoch 332/500\n",
      "404/404 [==============================] - 0s 837us/sample - loss: 5.6334 - val_loss: 22.6246\n",
      "Epoch 333/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 5.6774 - val_loss: 17.6037\n",
      "Epoch 334/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 5.9628 - val_loss: 18.8729\n",
      "Epoch 335/500\n",
      "404/404 [==============================] - 0s 951us/sample - loss: 5.4542 - val_loss: 21.9026\n",
      "Epoch 336/500\n",
      "404/404 [==============================] - 0s 947us/sample - loss: 5.3229 - val_loss: 19.6862\n",
      "Epoch 337/500\n",
      "404/404 [==============================] - 0s 848us/sample - loss: 6.7772 - val_loss: 20.4197\n",
      "Epoch 338/500\n",
      "404/404 [==============================] - 0s 942us/sample - loss: 6.0474 - val_loss: 18.6730\n",
      "Epoch 339/500\n",
      "404/404 [==============================] - 0s 975us/sample - loss: 5.6344 - val_loss: 20.7832\n",
      "Epoch 340/500\n",
      "404/404 [==============================] - 0s 961us/sample - loss: 6.0453 - val_loss: 19.7218\n",
      "Epoch 341/500\n",
      "404/404 [==============================] - 0s 941us/sample - loss: 5.4998 - val_loss: 19.8465\n",
      "Epoch 342/500\n",
      "404/404 [==============================] - 0s 905us/sample - loss: 6.0247 - val_loss: 19.5086\n",
      "Epoch 343/500\n",
      "404/404 [==============================] - 0s 905us/sample - loss: 5.4754 - val_loss: 20.2946\n",
      "Epoch 344/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 5.6374 - val_loss: 20.9270\n",
      "Epoch 345/500\n",
      "404/404 [==============================] - 0s 748us/sample - loss: 5.1923 - val_loss: 19.1943\n",
      "Epoch 346/500\n",
      "404/404 [==============================] - 0s 710us/sample - loss: 5.3585 - val_loss: 20.5013\n",
      "Epoch 347/500\n",
      "404/404 [==============================] - 0s 696us/sample - loss: 5.4679 - val_loss: 20.4267\n",
      "Epoch 348/500\n",
      "404/404 [==============================] - 0s 793us/sample - loss: 6.4552 - val_loss: 19.2874\n",
      "Epoch 349/500\n",
      "404/404 [==============================] - 0s 859us/sample - loss: 5.3230 - val_loss: 18.7776\n",
      "Epoch 350/500\n",
      "404/404 [==============================] - 0s 719us/sample - loss: 6.7181 - val_loss: 17.9899\n",
      "Epoch 351/500\n",
      "404/404 [==============================] - 0s 895us/sample - loss: 5.4065 - val_loss: 18.9096\n",
      "Epoch 352/500\n",
      "404/404 [==============================] - 0s 936us/sample - loss: 5.3890 - val_loss: 18.4195\n",
      "Epoch 353/500\n",
      "404/404 [==============================] - 0s 906us/sample - loss: 5.3118 - val_loss: 18.8199\n",
      "Epoch 354/500\n",
      "404/404 [==============================] - 0s 926us/sample - loss: 5.1334 - val_loss: 18.2033\n",
      "Epoch 355/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 6.2340 - val_loss: 23.5119\n",
      "Epoch 356/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 6.7894 - val_loss: 19.9407\n",
      "Epoch 357/500\n",
      "404/404 [==============================] - 0s 924us/sample - loss: 5.5660 - val_loss: 18.7651\n",
      "Epoch 358/500\n",
      "404/404 [==============================] - 0s 731us/sample - loss: 5.4962 - val_loss: 20.4966\n",
      "Epoch 359/500\n",
      "404/404 [==============================] - 0s 893us/sample - loss: 5.6233 - val_loss: 19.1211\n",
      "Epoch 360/500\n",
      "404/404 [==============================] - 0s 900us/sample - loss: 5.5159 - val_loss: 20.2038\n",
      "Epoch 361/500\n",
      "404/404 [==============================] - 0s 987us/sample - loss: 6.0876 - val_loss: 18.3027\n",
      "Epoch 362/500\n",
      "404/404 [==============================] - 0s 842us/sample - loss: 5.6173 - val_loss: 19.7671\n",
      "Epoch 363/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 5.6123 - val_loss: 18.9170\n",
      "Epoch 364/500\n",
      "404/404 [==============================] - 0s 952us/sample - loss: 5.2112 - val_loss: 18.4437\n",
      "Epoch 365/500\n",
      "404/404 [==============================] - 0s 739us/sample - loss: 5.2381 - val_loss: 19.0542\n",
      "Epoch 366/500\n",
      "404/404 [==============================] - 0s 763us/sample - loss: 5.7118 - val_loss: 22.7126\n",
      "Epoch 367/500\n",
      "404/404 [==============================] - 0s 775us/sample - loss: 5.6714 - val_loss: 17.9711\n",
      "Epoch 368/500\n",
      "404/404 [==============================] - 0s 790us/sample - loss: 5.2688 - val_loss: 19.6444\n",
      "Epoch 369/500\n",
      "404/404 [==============================] - 0s 912us/sample - loss: 5.0413 - val_loss: 18.0811\n",
      "Epoch 370/500\n",
      "404/404 [==============================] - 0s 856us/sample - loss: 5.7005 - val_loss: 20.3271\n",
      "Epoch 371/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 6.3201 - val_loss: 19.3315\n",
      "Epoch 372/500\n",
      "404/404 [==============================] - 0s 592us/sample - loss: 5.5092 - val_loss: 18.8303\n",
      "Epoch 373/500\n",
      "404/404 [==============================] - 0s 480us/sample - loss: 4.9853 - val_loss: 18.6177\n",
      "Epoch 374/500\n",
      "404/404 [==============================] - 0s 391us/sample - loss: 4.9746 - val_loss: 27.4063\n",
      "Epoch 375/500\n",
      "404/404 [==============================] - 0s 728us/sample - loss: 6.4085 - val_loss: 18.3551\n",
      "Epoch 376/500\n",
      "404/404 [==============================] - 0s 592us/sample - loss: 5.3666 - val_loss: 20.4600\n",
      "Epoch 377/500\n",
      "404/404 [==============================] - 0s 482us/sample - loss: 5.7368 - val_loss: 18.0916\n",
      "Epoch 378/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 388us/sample - loss: 6.0078 - val_loss: 19.3792\n",
      "Epoch 379/500\n",
      "404/404 [==============================] - 0s 374us/sample - loss: 4.9818 - val_loss: 18.0005\n",
      "Epoch 380/500\n",
      "404/404 [==============================] - 0s 370us/sample - loss: 5.1416 - val_loss: 24.6684\n",
      "Epoch 381/500\n",
      "404/404 [==============================] - 0s 439us/sample - loss: 5.5638 - val_loss: 22.9747\n",
      "Epoch 382/500\n",
      "404/404 [==============================] - 0s 485us/sample - loss: 5.4154 - val_loss: 18.2127\n",
      "Epoch 383/500\n",
      "404/404 [==============================] - 0s 388us/sample - loss: 5.1682 - val_loss: 21.0140\n",
      "Epoch 384/500\n",
      "404/404 [==============================] - 0s 375us/sample - loss: 4.7747 - val_loss: 19.3200\n",
      "Epoch 385/500\n",
      "404/404 [==============================] - 0s 375us/sample - loss: 5.0972 - val_loss: 18.1991\n",
      "Epoch 386/500\n",
      "404/404 [==============================] - 0s 551us/sample - loss: 5.0358 - val_loss: 17.6170\n",
      "Epoch 387/500\n",
      "404/404 [==============================] - 0s 484us/sample - loss: 5.1605 - val_loss: 17.8639\n",
      "Epoch 388/500\n",
      "404/404 [==============================] - 0s 383us/sample - loss: 4.9331 - val_loss: 21.8591\n",
      "Epoch 389/500\n",
      "404/404 [==============================] - 0s 385us/sample - loss: 5.6483 - val_loss: 18.0692\n",
      "Epoch 390/500\n",
      "404/404 [==============================] - 0s 376us/sample - loss: 5.4421 - val_loss: 19.8206\n",
      "Epoch 391/500\n",
      "404/404 [==============================] - 0s 495us/sample - loss: 5.0508 - val_loss: 18.7992\n",
      "Epoch 392/500\n",
      "404/404 [==============================] - 0s 544us/sample - loss: 5.1842 - val_loss: 17.0004\n",
      "Epoch 393/500\n",
      "404/404 [==============================] - 0s 829us/sample - loss: 5.0024 - val_loss: 19.1261\n",
      "Epoch 394/500\n",
      "404/404 [==============================] - 0s 538us/sample - loss: 4.9575 - val_loss: 22.9129\n",
      "Epoch 395/500\n",
      "404/404 [==============================] - 0s 890us/sample - loss: 5.0132 - val_loss: 18.1763\n",
      "Epoch 396/500\n",
      "404/404 [==============================] - 0s 923us/sample - loss: 4.6126 - val_loss: 18.9483\n",
      "Epoch 397/500\n",
      "404/404 [==============================] - 0s 846us/sample - loss: 5.6324 - val_loss: 17.4717\n",
      "Epoch 398/500\n",
      "404/404 [==============================] - 0s 774us/sample - loss: 5.4741 - val_loss: 19.5825\n",
      "Epoch 399/500\n",
      "404/404 [==============================] - 0s 740us/sample - loss: 5.0932 - val_loss: 18.4771\n",
      "Epoch 400/500\n",
      "404/404 [==============================] - 0s 846us/sample - loss: 5.7178 - val_loss: 20.7077\n",
      "Epoch 401/500\n",
      "404/404 [==============================] - 0s 876us/sample - loss: 5.5253 - val_loss: 20.8381\n",
      "Epoch 402/500\n",
      "404/404 [==============================] - 0s 987us/sample - loss: 5.0349 - val_loss: 21.1179\n",
      "Epoch 403/500\n",
      "404/404 [==============================] - 0s 905us/sample - loss: 5.3650 - val_loss: 17.5593\n",
      "Epoch 404/500\n",
      "404/404 [==============================] - 0s 933us/sample - loss: 4.6471 - val_loss: 19.1661\n",
      "Epoch 405/500\n",
      "404/404 [==============================] - 0s 831us/sample - loss: 5.0622 - val_loss: 16.7465\n",
      "Epoch 406/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 4.9121 - val_loss: 17.0436\n",
      "Epoch 407/500\n",
      "404/404 [==============================] - 0s 958us/sample - loss: 4.7655 - val_loss: 17.2822\n",
      "Epoch 408/500\n",
      "404/404 [==============================] - 0s 914us/sample - loss: 4.8888 - val_loss: 18.8783\n",
      "Epoch 409/500\n",
      "404/404 [==============================] - 0s 877us/sample - loss: 4.8302 - val_loss: 18.6778\n",
      "Epoch 410/500\n",
      "404/404 [==============================] - 0s 891us/sample - loss: 4.7383 - val_loss: 18.2299\n",
      "Epoch 411/500\n",
      "404/404 [==============================] - 0s 752us/sample - loss: 4.6514 - val_loss: 17.7964\n",
      "Epoch 412/500\n",
      "404/404 [==============================] - 0s 733us/sample - loss: 4.5818 - val_loss: 20.0130\n",
      "Epoch 413/500\n",
      "404/404 [==============================] - 0s 907us/sample - loss: 5.1029 - val_loss: 19.1757\n",
      "Epoch 414/500\n",
      "404/404 [==============================] - 0s 806us/sample - loss: 5.3344 - val_loss: 21.1903\n",
      "Epoch 415/500\n",
      "404/404 [==============================] - 0s 821us/sample - loss: 4.7050 - val_loss: 17.4450\n",
      "Epoch 416/500\n",
      "404/404 [==============================] - 0s 739us/sample - loss: 4.5964 - val_loss: 18.5040\n",
      "Epoch 417/500\n",
      "404/404 [==============================] - 0s 820us/sample - loss: 4.8467 - val_loss: 18.5352\n",
      "Epoch 418/500\n",
      "404/404 [==============================] - 0s 923us/sample - loss: 6.0814 - val_loss: 20.9748\n",
      "Epoch 419/500\n",
      "404/404 [==============================] - 0s 866us/sample - loss: 5.0012 - val_loss: 18.6946\n",
      "Epoch 420/500\n",
      "404/404 [==============================] - 0s 723us/sample - loss: 4.6193 - val_loss: 18.1288\n",
      "Epoch 421/500\n",
      "404/404 [==============================] - 0s 890us/sample - loss: 4.9177 - val_loss: 17.3874\n",
      "Epoch 422/500\n",
      "404/404 [==============================] - 0s 859us/sample - loss: 4.9349 - val_loss: 17.1593\n",
      "Epoch 423/500\n",
      "404/404 [==============================] - 0s 714us/sample - loss: 5.4926 - val_loss: 20.6567\n",
      "Epoch 424/500\n",
      "404/404 [==============================] - 0s 838us/sample - loss: 5.0812 - val_loss: 18.8985\n",
      "Epoch 425/500\n",
      "404/404 [==============================] - 0s 856us/sample - loss: 6.1425 - val_loss: 20.9811\n",
      "Epoch 426/500\n",
      "404/404 [==============================] - 0s 774us/sample - loss: 4.7494 - val_loss: 17.6563\n",
      "Epoch 427/500\n",
      "404/404 [==============================] - 0s 845us/sample - loss: 4.7405 - val_loss: 18.1872\n",
      "Epoch 428/500\n",
      "404/404 [==============================] - 0s 725us/sample - loss: 5.0858 - val_loss: 19.2947\n",
      "Epoch 429/500\n",
      "404/404 [==============================] - 0s 808us/sample - loss: 5.1535 - val_loss: 19.0636\n",
      "Epoch 430/500\n",
      "404/404 [==============================] - 0s 799us/sample - loss: 5.0620 - val_loss: 22.0651\n",
      "Epoch 431/500\n",
      "404/404 [==============================] - ETA: 0s - loss: 4.725 - 0s 817us/sample - loss: 4.6737 - val_loss: 18.7132\n",
      "Epoch 432/500\n",
      "404/404 [==============================] - 0s 823us/sample - loss: 4.5142 - val_loss: 18.1574\n",
      "Epoch 433/500\n",
      "404/404 [==============================] - 0s 826us/sample - loss: 5.2041 - val_loss: 18.0325\n",
      "Epoch 434/500\n",
      "404/404 [==============================] - 0s 845us/sample - loss: 4.5139 - val_loss: 18.6463\n",
      "Epoch 435/500\n",
      "404/404 [==============================] - 0s 792us/sample - loss: 4.4774 - val_loss: 19.2386\n",
      "Epoch 436/500\n",
      "404/404 [==============================] - 0s 777us/sample - loss: 4.7674 - val_loss: 27.4564\n",
      "Epoch 437/500\n",
      "404/404 [==============================] - 0s 783us/sample - loss: 5.2163 - val_loss: 17.7994\n",
      "Epoch 438/500\n",
      "404/404 [==============================] - 0s 804us/sample - loss: 4.3549 - val_loss: 17.0881\n",
      "Epoch 439/500\n",
      "404/404 [==============================] - 0s 840us/sample - loss: 4.8234 - val_loss: 19.7434\n",
      "Epoch 440/500\n",
      "404/404 [==============================] - 0s 827us/sample - loss: 4.6694 - val_loss: 16.3334\n",
      "Epoch 441/500\n",
      "404/404 [==============================] - 0s 758us/sample - loss: 4.2721 - val_loss: 17.4171\n",
      "Epoch 442/500\n",
      "404/404 [==============================] - 0s 809us/sample - loss: 4.4279 - val_loss: 17.9545\n",
      "Epoch 443/500\n",
      "404/404 [==============================] - 0s 786us/sample - loss: 5.1699 - val_loss: 19.1638\n",
      "Epoch 444/500\n",
      "404/404 [==============================] - 0s 671us/sample - loss: 4.2954 - val_loss: 16.9155\n",
      "Epoch 445/500\n",
      "404/404 [==============================] - 0s 721us/sample - loss: 5.8058 - val_loss: 18.1059\n",
      "Epoch 446/500\n",
      "404/404 [==============================] - 0s 691us/sample - loss: 4.6082 - val_loss: 17.3920\n",
      "Epoch 447/500\n",
      "404/404 [==============================] - 0s 666us/sample - loss: 5.4419 - val_loss: 16.9104\n",
      "Epoch 448/500\n",
      "404/404 [==============================] - 0s 784us/sample - loss: 4.2827 - val_loss: 18.5025\n",
      "Epoch 449/500\n",
      "404/404 [==============================] - 0s 889us/sample - loss: 4.3935 - val_loss: 19.6691\n",
      "Epoch 450/500\n",
      "404/404 [==============================] - 0s 844us/sample - loss: 4.5641 - val_loss: 16.8252\n",
      "Epoch 451/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 4.9502 - val_loss: 19.4237\n",
      "Epoch 452/500\n",
      "404/404 [==============================] - 0s 820us/sample - loss: 4.6751 - val_loss: 17.9433\n",
      "Epoch 453/500\n",
      "404/404 [==============================] - 0s 547us/sample - loss: 5.9938 - val_loss: 18.8490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454/500\n",
      "404/404 [==============================] - 0s 474us/sample - loss: 4.4875 - val_loss: 18.0077\n",
      "Epoch 455/500\n",
      "404/404 [==============================] - 0s 453us/sample - loss: 5.3236 - val_loss: 20.2198\n",
      "Epoch 456/500\n",
      "404/404 [==============================] - 0s 796us/sample - loss: 4.6287 - val_loss: 18.4441\n",
      "Epoch 457/500\n",
      "404/404 [==============================] - 0s 606us/sample - loss: 4.8609 - val_loss: 16.7045\n",
      "Epoch 458/500\n",
      "404/404 [==============================] - 0s 494us/sample - loss: 5.2219 - val_loss: 17.6080\n",
      "Epoch 459/500\n",
      "404/404 [==============================] - 0s 384us/sample - loss: 4.2262 - val_loss: 17.5995\n",
      "Epoch 460/500\n",
      "404/404 [==============================] - 0s 380us/sample - loss: 4.1655 - val_loss: 17.0909\n",
      "Epoch 461/500\n",
      "404/404 [==============================] - 0s 376us/sample - loss: 4.3143 - val_loss: 17.5685\n",
      "Epoch 462/500\n",
      "404/404 [==============================] - 0s 465us/sample - loss: 4.5300 - val_loss: 16.7876\n",
      "Epoch 463/500\n",
      "404/404 [==============================] - 0s 440us/sample - loss: 4.2193 - val_loss: 17.5455\n",
      "Epoch 464/500\n",
      "404/404 [==============================] - 0s 368us/sample - loss: 4.3103 - val_loss: 17.6589\n",
      "Epoch 465/500\n",
      "404/404 [==============================] - 0s 368us/sample - loss: 4.4708 - val_loss: 18.2079\n",
      "Epoch 466/500\n",
      "404/404 [==============================] - 0s 389us/sample - loss: 4.6366 - val_loss: 17.6013\n",
      "Epoch 467/500\n",
      "404/404 [==============================] - 0s 511us/sample - loss: 4.2711 - val_loss: 18.1892\n",
      "Epoch 468/500\n",
      "404/404 [==============================] - 0s 360us/sample - loss: 4.9491 - val_loss: 18.2998\n",
      "Epoch 469/500\n",
      "404/404 [==============================] - 0s 417us/sample - loss: 4.5010 - val_loss: 16.5462\n",
      "Epoch 470/500\n",
      "404/404 [==============================] - 0s 462us/sample - loss: 4.9915 - val_loss: 16.4306\n",
      "Epoch 471/500\n",
      "404/404 [==============================] - 0s 640us/sample - loss: 4.7022 - val_loss: 16.4331\n",
      "Epoch 472/500\n",
      "404/404 [==============================] - 0s 933us/sample - loss: 4.4484 - val_loss: 16.1643\n",
      "Epoch 473/500\n",
      "404/404 [==============================] - 0s 786us/sample - loss: 4.5087 - val_loss: 16.8052\n",
      "Epoch 474/500\n",
      "404/404 [==============================] - 0s 825us/sample - loss: 4.4250 - val_loss: 17.5063\n",
      "Epoch 475/500\n",
      "404/404 [==============================] - 0s 835us/sample - loss: 4.7288 - val_loss: 16.9913\n",
      "Epoch 476/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 4.1799 - val_loss: 17.3224\n",
      "Epoch 477/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 4.6412 - val_loss: 17.0773\n",
      "Epoch 478/500\n",
      "404/404 [==============================] - 0s 1ms/sample - loss: 4.3591 - val_loss: 16.7342\n",
      "Epoch 479/500\n",
      "404/404 [==============================] - 0s 739us/sample - loss: 4.0387 - val_loss: 17.2990\n",
      "Epoch 480/500\n",
      "404/404 [==============================] - 0s 757us/sample - loss: 4.2818 - val_loss: 16.5597\n",
      "Epoch 481/500\n",
      "404/404 [==============================] - 0s 842us/sample - loss: 4.4455 - val_loss: 16.9980\n",
      "Epoch 482/500\n",
      "404/404 [==============================] - 0s 958us/sample - loss: 4.4355 - val_loss: 19.4815\n",
      "Epoch 483/500\n",
      "404/404 [==============================] - 0s 856us/sample - loss: 4.2049 - val_loss: 16.7173\n",
      "Epoch 484/500\n",
      "404/404 [==============================] - 0s 798us/sample - loss: 4.0606 - val_loss: 19.0014\n",
      "Epoch 485/500\n",
      "404/404 [==============================] - 0s 899us/sample - loss: 4.3291 - val_loss: 17.2780\n",
      "Epoch 486/500\n",
      "404/404 [==============================] - 0s 748us/sample - loss: 4.2805 - val_loss: 17.3789\n",
      "Epoch 487/500\n",
      "404/404 [==============================] - 0s 881us/sample - loss: 4.0395 - val_loss: 16.8143\n",
      "Epoch 488/500\n",
      "404/404 [==============================] - 0s 835us/sample - loss: 3.9137 - val_loss: 17.5050\n",
      "Epoch 489/500\n",
      "404/404 [==============================] - 0s 960us/sample - loss: 4.3332 - val_loss: 17.1825\n",
      "Epoch 490/500\n",
      "404/404 [==============================] - 0s 987us/sample - loss: 4.4296 - val_loss: 16.9807\n",
      "Epoch 491/500\n",
      "404/404 [==============================] - 0s 992us/sample - loss: 3.9991 - val_loss: 17.4501\n",
      "Epoch 492/500\n",
      "404/404 [==============================] - 0s 865us/sample - loss: 4.4205 - val_loss: 17.9346\n",
      "Epoch 493/500\n",
      "404/404 [==============================] - 0s 964us/sample - loss: 4.2533 - val_loss: 17.5083\n",
      "Epoch 494/500\n",
      "404/404 [==============================] - 0s 932us/sample - loss: 3.9088 - val_loss: 16.5607\n",
      "Epoch 495/500\n",
      "404/404 [==============================] - 0s 769us/sample - loss: 4.2546 - val_loss: 17.8198\n",
      "Epoch 496/500\n",
      "404/404 [==============================] - 0s 680us/sample - loss: 3.8621 - val_loss: 17.3731\n",
      "Epoch 497/500\n",
      "404/404 [==============================] - 0s 817us/sample - loss: 4.4527 - val_loss: 19.3965\n",
      "Epoch 498/500\n",
      "404/404 [==============================] - 0s 779us/sample - loss: 4.9855 - val_loss: 19.7583\n",
      "Epoch 499/500\n",
      "404/404 [==============================] - 0s 942us/sample - loss: 3.9630 - val_loss: 17.0293\n",
      "Epoch 500/500\n",
      "404/404 [==============================] - 0s 957us/sample - loss: 4.2114 - val_loss: 16.8956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f14fd7e1f98>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model_five.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=500, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train : 3.588379811611446\n",
      "MSE test:  16.89561614998553\n"
     ]
    }
   ],
   "source": [
    "print('MSE train :', mean_squared_error(my_model_five.predict(X_train), y_train))\n",
    "print('MSE test: ', mean_squared_error(my_model_five.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_output_at() missing 1 required positional argument: 'node_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-d722169cc639>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_model_five\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: get_output_at() missing 1 required positional argument: 'node_index'"
     ]
    }
   ],
   "source": [
    "my_model_five.get_output_at()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Sklearn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on train LR: 19.32647020358573\n",
      "MSE on test LR: 33.448979997676545\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print('MSE on train LR:', mean_squared_error(lr.predict(X_train), y_train))\n",
    "print('MSE on test LR:', mean_squared_error(lr.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
